# -*- coding: utf-8 -*-
"""Dataset2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18mDPpQdb9IwJEguEzE2RegreAf_hqId_
"""

# Importing all necessary library and setting up spark context

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import os
import shutil
import numpy as np
import plotly.express as px
from sklearn.model_selection import train_test_split, KFold, cross_validate, cross_val_score
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import LabelEncoder, OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
from pyspark import SparkContext, rdd
from pyspark.sql import SparkSession
from pyspark.sql import *
from pyspark.sql.functions import *
from pyspark.sql.types import *
sc = SparkContext.getOrCreate()
spark = SparkSession.builder.appName('ops').getOrCreate()
print(sc)
print(spark)


#Read CSV file fromm AWS s3 bucket

df = pd.read_csv("https://diadataset.s3.amazonaws.com/hotel_bookings.csv")
df.head()

#Data Cleaning Pre-processing and Visualization

df_cln = pd.DataFrame(df.fillna({"children": 0.0, "country": "Unknown", "agent": 0, "company": 0}))
df_cln["meal"].replace("Undefined", "SC", inplace = True)
noguests = list(df_cln.loc[df_cln["adults"] + df_cln["children"] + df_cln["babies"]==0].index)
df_cln.drop(df_cln.index[noguests], inplace=True)
hotel_cancellation = df_cln.copy()
hotel_cancellation['hotel'].value_counts()
sns.set_style("whitegrid")
plt.figure(figsize=(13,5))
sns.countplot(x='is_canceled', hue='hotel', data=hotel_cancellation)
plt.title('Hotels Cancellation Graph')
plt.show()
hotel_cancellation['is_canceled'].value_counts()/df_cln.shape[0]*100


#This shows total guest arrived across the period

country_data = pd.DataFrame(df_cln.loc[df_cln["is_canceled"] == 0]["country"].value_counts())
country_data.rename(columns={"country": "Number of Guests"}, inplace=True)
total_guests = country_data["Number of Guests"].sum()
country_data["Guests in %age"] = round(country_data["Number of Guests"] / total_guests * 100)
country_data["country"] = country_data.index
total_guests


#Pie Plot of guests coming from home country

fig = px.pie(country_data, values="Number of Guests", names="country", title="Guests arriving from Country", template="seaborn")
fig.update_traces(textposition="inside", textinfo="value+percent+label")
fig.show()


#This show the average number of guests arrived per month for both Hotels

resort_hotel = df_cln.loc[(df_cln["hotel"] == "Resort Hotel") & (df_cln["is_canceled"] == 0)]
city_hotel = df_cln.loc[(df_cln["hotel"] == "City Hotel") & (df_cln["is_canceled"] == 0)]

resort_guests_monthly = resort_hotel.groupby("arrival_date_month")["hotel"].count()
city_guests_monthly = city_hotel.groupby("arrival_date_month")["hotel"].count()

resort_guest_data = pd.DataFrame({"month": list(resort_guests_monthly.index), "hotel": "Resort hotel", "guests": list(resort_guests_monthly.values)})
city_guest_data = pd.DataFrame({"month": list(city_guests_monthly.index), "hotel": "City hotel", "guests": list(city_guests_monthly.values)})

full_guest_data = pd.concat([resort_guest_data,city_guest_data], ignore_index=True)

ordered_months = ["January", "February", "March", "April", "May", "June", "July", "August", "September", "October", "November", "December"]
full_guest_data["month"] = pd.Categorical(full_guest_data["month"], categories=ordered_months, ordered=True)
full_guest_data


#Line Plot shows highest number of guests month wise

sns.set(style="whitegrid")
plt.figure(figsize=(13, 5))
sns.lineplot(x = "month", y="guests", hue="hotel", data=full_guest_data, hue_order = ["City hotel", "Resort hotel"], size="hotel", sizes=(2.5, 2.5))
plt.title("Average number of hotel guests per month", fontsize=16)
plt.xlabel("Month", fontsize=16)
plt.ylabel("Number of guests", fontsize=16)
plt.show()


#This shows booking cancelled for both the hotels across the months

rh_book_per_month = df_cln.loc[(df_cln["hotel"] == "Resort Hotel")].groupby("arrival_date_month")["hotel"].count()
rh_cancel_per_month = df_cln.loc[(df_cln["hotel"] == "Resort Hotel")].groupby("arrival_date_month")["is_canceled"].sum()

ch_book_per_month = df_cln.loc[(df_cln["hotel"] == "City Hotel")].groupby("arrival_date_month")["hotel"].count()
ch_cancel_per_month = df_cln.loc[(df_cln["hotel"] == "City Hotel")].groupby("arrival_date_month")["is_canceled"].sum()

rh_cancel_data = pd.DataFrame({"Hotel": "Resort Hotel","Month": list(rh_book_per_month.index),"Bookings": list(rh_book_per_month.values),"Cancelations": list(rh_cancel_per_month.values)})
ch_cancel_data = pd.DataFrame({"Hotel": "City Hotel","Month": list(ch_book_per_month.index),"Bookings": list(ch_book_per_month.values),"Cancelations": list(ch_cancel_per_month.values)})

df_cancel_data = pd.concat([rh_cancel_data, ch_cancel_data], ignore_index=True)
df_cancel_data["Cancel_Percent"] = df_cancel_data["Cancelations"] / df_cancel_data["Bookings"] * 100

ordered_months = ["January", "February", "March", "April", "May", "June", "July", "August", "September", "October", "November", "December"]
df_cancel_data["Month"] = pd.Categorical(df_cancel_data["Month"], categories=ordered_months, ordered=True)

df_cancel_data


#Bar Plot will show the cancellation per month

plt.figure(figsize=(13, 8))
sns.barplot(x = "Month", y = "Cancel_Percent" , hue="Hotel", hue_order = ["City Hotel", "Resort Hotel"], data=df_cancel_data)
plt.title("Cancelations per month", fontsize=16)
plt.xlabel("Month", fontsize=16)
plt.ylabel("Cancelations %age", fontsize=16)
plt.show()


# Pairwise correlation of columns

corr_cancel = df.corr()["is_canceled"]
corr_cancel.abs().sort_values(ascending=False)[1:]


#SimpleImputer and Pipeline function for preprocessor

numerical_features = ["lead_time","arrival_date_week_number","arrival_date_day_of_month","stays_in_weekend_nights","stays_in_week_nights","adults","children",
                "babies","is_repeated_guest", "previous_cancellations","previous_bookings_not_canceled","agent","company",
                "required_car_parking_spaces", "total_of_special_requests", "adr"]

categorical_features = ["hotel","arrival_date_month","meal","market_segment","distribution_channel","reserved_room_type","deposit_type","customer_type"]

features = numerical_features + categorical_features
X = df.drop(["is_canceled"], axis=1)[features]
y = df["is_canceled"]

numerical_transformer = SimpleImputer(strategy="constant")

categorical_transformer = Pipeline(steps=[("imputer", SimpleImputer(strategy="constant", fill_value="Unknown")),
    ("onehot", OneHotEncoder(handle_unknown='ignore'))])

preprocessor = ColumnTransformer(transformers=[("num", numerical_transformer, numerical_features),
                                               ("cat", categorical_transformer, categorical_features)])


#Cross-validation score on different models

models = [("DTree", DecisionTreeClassifier(random_state=40)), ("RForest", RandomForestClassifier(random_state=40,n_jobs=-1)),
               ("LogReg", LogisticRegression(random_state=40,n_jobs=-1)), ("XGBoost", XGBClassifier(random_state=40, n_jobs=-1))]
kfolds = 4
split = KFold(n_splits=kfolds, shuffle=True, random_state=40)
Results = []
for name, model in models:
    data_dict = {"ModelName":[],"Accuracy":[],"Standard_deviation":[],"Min.Score":[],"Max.Score":[]}
    model_steps = Pipeline(steps=[('preprocessor', preprocessor), ('model', model)])
    cross_val = cross_val_score(model_steps, X, y, cv=split, scoring="accuracy", n_jobs=-1)
    data_dict["ModelName"] = name
    min_score = round(min(cross_val), 4)
    data_dict["Min.Score"] = min_score
    max_score = round(max(cross_val), 4)
    data_dict["Max.Score"] = max_score
    mean_score = round(np.mean(cross_val), 4)
    data_dict["Accuracy"] = mean_score
    std_dev = round(np.std(cross_val), 4)
    data_dict["Standard_deviation"] = std_dev
    print(f"{name} cross validation accuracy score: {mean_score} +/- {std_dev} (std) min: {min_score}, max: {max_score}")
    Results.append(data_dict)
    
final = pd.DataFrame().from_dict(Results)
final.head()

final.set_index('ModelName', inplace=True)
final['Accuracy'].plot(kind='barh', figsize=(12, 8))


#Reg plot for showing important feature using correlation

lead_cancel_data = df_cln.groupby("lead_time")["is_canceled"].describe()
lead_cancel_data_10 = lead_cancel_data.loc[lead_cancel_data["count"] >= 10]
plt.figure(figsize=(12, 8))
sns.regplot(x=lead_cancel_data_10.index, y=lead_cancel_data_10["mean"].values * 100)
plt.title("Effect of lead time on cancelation", fontsize=16)
plt.xlabel("Lead time", fontsize=16)
plt.ylabel("Cancelations %age", fontsize=16)
plt.show()


#Converting  DataFrame into RDD

rdd = spark.createDataFrame(df_cln).rdd

#Using Mao and Lamda function for fetching the output

rdd = rdd.map(lambda row: [str(c) for c in row])
rdd_new = rdd.map(lambda x: (x[0],x[30],x[31])).sortBy(lambda a: a[0])


#Result Output

rdd_new.take(200000)


#Output is being published in HDFS

rdd_new.saveAsTextFile("Dataset1_output")


